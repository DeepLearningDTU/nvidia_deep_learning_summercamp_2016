{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.datasets\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural networks 101\n",
    "\n",
    "Convolution neural networks are one of the most succesfull types of neural networks for image recognition and an integral part of reigniting the interest in neural networks. \n",
    "\n",
    "In this lab we'll experiment with inserting 2D-convolution layers in the fully connected neural networks introduced in LAB1. We'll furhter experiment with stacking of convolution layers, max pooling and strided convolutions which are all important techniques in current convolution neural networks. Lastly we'll try to visualize the learned convolution filters and try to understand what kind of features they learn to recognize.\n",
    "\n",
    "\n",
    "If you are unfamilar with the the convolution operation  https://github.com/vdumoulin/conv_arithmetic have a nice visualization of different convolution variants. For a more indept tutorial please see http://cs231n.github.io/convolutional-networks/ or http://neuralnetworksanddeeplearning.com/chap6.html. Lastly if you are ambitious and want implement a convolution neural network from scratch please see an exercise for our Deep Learning summer school last year https://github.com/DTU-deeplearning/day2-Conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#LOAD the mnist data. To speed up training we'll only work on a subset of the data.\n",
    "#Note that we reshape the data from (nsamples, num_features)= (nsamples, nchannels*rows*cols)  -> (nsamples, nchannels, rows, cols)\n",
    "# in order to retain the spatial arrangements of the pixels\n",
    "data = np.load('mnist.npz')\n",
    "num_classes = 10\n",
    "nchannels,rows,cols = 1,28,28\n",
    "x_train = data['X_train'][:10000].astype('float32')\n",
    "x_train = x_train.reshape((-1,nchannels,rows,cols))\n",
    "targets_train = data['y_train'][:10000].astype('int32')\n",
    "\n",
    "x_valid = data['X_valid'][:500].astype('float32')\n",
    "x_valid = x_valid.reshape((-1,nchannels,rows,cols))\n",
    "targets_valid = data['y_valid'][:500].astype('int32')\n",
    "\n",
    "x_test = data['X_test'][:500].astype('float32')\n",
    "x_test = x_test.reshape((-1,nchannels,rows,cols))\n",
    "targets_test = data['y_test'][:500].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot a few MNIST examples\n",
    "idx = 0\n",
    "canvas = np.zeros((28*10, 10*28))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        canvas[i*28:(i+1)*28, j*28:(j+1)*28] = x_train[idx].reshape((28, 28))\n",
    "        idx += 1\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.imshow(canvas, cmap='gray')\n",
    "plt.title('MNIST handwritten digits')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a simple feed forward neural network\n",
    "\n",
    "from lasagne.nonlinearities import leaky_rectify, softmax, tanh, elu\n",
    "from lasagne.layers import InputLayer, DenseLayer, Conv2DLayer, batch_norm, DropoutLayer, MaxPool2DLayer\n",
    "\n",
    "#defined the model\n",
    "num_class = 10\n",
    "num_features = x_train.shape[1]\n",
    "\n",
    "l_in = InputLayer(shape=(None,nchannels,rows,cols)) #note that we use a 4D input since we need to retain the spatial arrangement of the pixels when working with convolutions.\n",
    "#l_conv = Conv2DLayer(l_in,num_filters=16,filter_size=5)\n",
    "l_hid = DenseLayer(l_in, num_units=100, nonlinearity=elu) #remember to connect the new conv-layer here\n",
    "l_out = DenseLayer(l_hid, num_units=num_class, nonlinearity=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setting up the graph in theano\n",
    "sym_x = T.tensor4('sym_x') # a symbolic variable, this is now a 4-D tensor.\n",
    "sym_t = T.ivector('sym_t') # a symbolic variable taking on the value of the target batch.\n",
    "\n",
    "# Get network output\n",
    "train_out = lasagne.layers.get_output(l_out, sym_x, deterministic=False)\n",
    "eval_out = lasagne.layers.get_output(l_out, sym_x, deterministic=True)\n",
    "\n",
    "\n",
    "# Get list of all trainable parameters in the network.\n",
    "all_params = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "\n",
    "cost = T.nnet.categorical_crossentropy(train_out+1e-8, sym_t).mean()\n",
    "# Let Theano do its magic and get all the gradients we need for training\n",
    "all_grads = T.grad(cost, all_params)\n",
    "\n",
    "\n",
    "# Set the update function for parameters \n",
    "# you might wan't to experiment with more advanded update schemes like rmsprob, adadelta etc.\n",
    "updates = lasagne.updates.adam(all_grads, all_params, learning_rate=0.001)\n",
    "\n",
    "\n",
    "f_eval = theano.function([sym_x],\n",
    "                     eval_out, on_unused_input='warn')\n",
    "\n",
    "f_train = theano.function([sym_x, sym_t],\n",
    "                          [cost],\n",
    "                          updates=updates, on_unused_input='warn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test the forward pass\n",
    "x = np.random.normal(0,1, (45, 1,28,28)).astype('float32') #dummy data\n",
    "\n",
    "model = lasagne.layers.get_output(l_out, sym_x)\n",
    "out = model.eval({sym_x:x}) #this could also include mask etc if used\n",
    "print(\"l_out\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Training Loop\n",
    "from confusionmatrix import ConfusionMatrix\n",
    "batch_size = 100\n",
    "num_epochs = 20\n",
    "num_samples_train = x_train.shape[0]\n",
    "num_batches_train = num_samples_train // batch_size\n",
    "num_samples_valid = x_valid.shape[0]\n",
    "num_batches_valid = num_samples_valid // batch_size\n",
    "\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "test_acc, test_loss = [], []\n",
    "cur_loss = 0\n",
    "loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    #Forward->Backprob->Update params\n",
    "    cur_loss = 0\n",
    "    for i in range(num_batches_train):\n",
    "        idx = range(i*batch_size, (i+1)*batch_size)\n",
    "        x_batch = x_train[idx]\n",
    "        target_batch = targets_train[idx]    \n",
    "        batch_loss = f_train(x_batch,target_batch) #this will do the complete backprob pass\n",
    "        cur_loss += batch_loss[0]\n",
    "    loss += [cur_loss/batch_size]\n",
    "    \n",
    "    confusion_valid = ConfusionMatrix(num_classes)\n",
    "    confusion_train = ConfusionMatrix(num_classes)\n",
    "\n",
    "    for i in range(num_batches_train):\n",
    "        idx = range(i*batch_size, (i+1)*batch_size)\n",
    "        x_batch = x_train[idx]\n",
    "        targets_batch = targets_train[idx]\n",
    "        net_out = f_eval(x_batch)   \n",
    "        preds = np.argmax(net_out, axis=-1) \n",
    "        confusion_train.batch_add(targets_batch, preds)\n",
    "\n",
    "    confusion_valid = ConfusionMatrix(num_classes)\n",
    "    for i in range(num_batches_valid):\n",
    "        idx = range(i*batch_size, (i+1)*batch_size)\n",
    "        x_batch = x_valid[idx]\n",
    "        targets_batch = targets_valid[idx]\n",
    "        net_out = f_eval(x_batch)   \n",
    "        preds = np.argmax(net_out, axis=-1) \n",
    "        \n",
    "        confusion_valid.batch_add(targets_batch, preds)\n",
    "    \n",
    "    train_acc_cur = confusion_train.accuracy()\n",
    "    valid_acc_cur = confusion_valid.accuracy()\n",
    "\n",
    "    train_acc += [train_acc_cur]\n",
    "    valid_acc += [valid_acc_cur]\n",
    "    print \"Epoch %i : Train Loss %e , Train acc %f,  Valid acc %f \" \\\n",
    "    % (epoch+1, loss[-1], train_acc_cur, valid_acc_cur)\n",
    "    \n",
    "\n",
    "#get test set score\n",
    "confusion_test = ConfusionMatrix(num_classes)\n",
    "net_out = f_eval(x_test)    \n",
    "preds = np.argmax(net_out, axis=-1) \n",
    "confusion_test.batch_add(targets_test, preds)\n",
    "print \"\\nTest set Acc:  %f\" %(confusion_test.accuracy())\n",
    "\n",
    "\n",
    "epoch = np.arange(len(train_acc))\n",
    "plt.figure()\n",
    "plt.plot(epoch,train_acc,'r',epoch,valid_acc,'b')\n",
    "plt.legend(['Train Acc','Val Acc'])\n",
    "plt.xlabel('Epochs'), plt.ylabel('Acc'), plt.ylim([0.75,1.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments 1\n",
    "\n",
    " 1) Note the performance of the standard feedforward neural network. Add a 2D convolution layer before the dense hidden layer and confirm that it increases the generalization performance of the network (try num_filters=16 and filter_size=5 as a starting point). \n",
    " \n",
    " 2) Can the performance be increases even further by stacking more convolution layers ?\n",
    " \n",
    " 3) Maxpooling is a technique for decreasing the spatial resolution of an image while retaining the important features. Effectively this gives a local translational invariance and reduces the computation by a factor of four. In the classification algorithm which is usually desirable. Try to either: \n",
    " \n",
    "     a) add a maxpool layer(add arguement pool_size=2)  after the convolution layer or\n",
    "     b) set add stride=2 to the arguments of the convolution layer. \n",
    "  Verify that this decreases spatial dimension of the image. (print l_conv.output_shape or print   l_maxpool.output_shape). Does this increase the performance of the network (you may need to stack multiple layers or increase the number of filters to increase performance) ?\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of filters\n",
    "Convolution filters can be interpreted as spatial feature detectors picking up different image features such as edges, corners etc. Below we provide code for visualization of the filters. The best results are obtained with fairly large filters of size 9 and either 16 or 36 filters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np_W = l_conv.W.get_value() #get the filter values from the conv layer\n",
    "print np_W.shape, \"i.e. the shape is num_filters, num_channels, filter_size, filter_size\"\n",
    "num_filters,num_channels,filter_size,_= np_W.shape\n",
    "n = int(num_filters**0.5)\n",
    "\n",
    "np_W_res = np_W.reshape(n,n,num_channels,filter_size,filter_size)\n",
    "fig, ax = plt.subplots(n,n)\n",
    "print \"learned filter values\"\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax[i,j].imshow(np_W_res[i,j,0], cmap='gray',interpolation='none')\n",
    "        ax[i,j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[i,j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n",
    "\n",
    "idx = 1\n",
    "plt.figure()\n",
    "plt.imshow(x_train[idx,0],cmap='gray',interpolation='none')\n",
    "plt.title('Inut Image')\n",
    "plt.show()\n",
    "\n",
    "#visalize the filters convolved with an input image\n",
    "from scipy.signal import convolve2d\n",
    "np_W_res = np_W.reshape(n,n,num_channels,filter_size,filter_size)\n",
    "fig, ax = plt.subplots(n,n,figsize=(9,9))\n",
    "print \"Response from input image convolved with the filters\"\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax[i,j].imshow(convolve2d(x_train[1,0],np_W_res[i,j,0],mode='same'), cmap='gray',interpolation='none')\n",
    "        ax[i,j].xaxis.set_major_formatter(plt.NullFormatter())\n",
    "        ax[i,j].yaxis.set_major_formatter(plt.NullFormatter())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignments 2\n",
    "\n",
    "The visualized filters will likely look most like noise due to the small amount of training data.\n",
    "\n",
    " 1) Try to use 10000 traning examples instead and visualise the filters again\n",
    " \n",
    " 2) Dropout is a very usefull technique for preventing overfitting. Try to add a DropoutLayer after the convolution layer and hidden layer. This should increase both performance and the \"visual appeal\" of the filters\n",
    " \n",
    " 3) Batch normalization is a recent innovation for improving generalization performance. Try to insert batch normalization layers into the network to improve performance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
