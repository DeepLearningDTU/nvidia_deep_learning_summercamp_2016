{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%matplotlib nbagg\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from data_generator import get_batch, print_valid_characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent neural networks are the natural type of neural network to use for sequential data i.e. time series analysis, translation, speech recognition etc. Recurrent neural networks works by recursively applying the same operation at each time step of the data sequence why the also naturally handle input of varying length. Recurrent networks can be used for several prediction tasks including: sequence-to-class, sequence tagging, and sequence-to-sequence predictions.\n",
    "\n",
    "In this exercise we'll implement a Encoder-Decoder RNN based on the GRU unit for a simple sequence to sequence translation task. This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "For more indept background material on RNNs please see [Supervised Sequence Labelling with Recurrent\n",
    "Neural Networks](https://www.cs.toronto.edu/~graves/preprint.pdf) by Alex Graves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder\n",
    "In the encoder-decoder structure one RNN (blue) encodes the input and a second RNN (red) calculates the target values. One essential step is to let the encoder and decoder communicate. In the simplest approach you use the last hidden state of the encoder to initialize the decoder. Other approaches lets the decoder attend to different parts of the encoded input at different timesteps in the decoding process. \n",
    "\n",
    "<img src=\"files/enc-dec.png\", width=400>\n",
    "\n",
    "In our implementation we use a RNN with gated recurrent units (GRU) as encoder. We then use the last hidden state of the encoder ($h^{enc}_T$) as input to the decoder which is also a GRU RNN. \n",
    "\n",
    "### RNNs in Lasagne\n",
    "Lasagne have implementations of LSTM and GRU unit. Both layers assume that the input from the layer below have the shape **(Batch_size, seq_len, num_features)**. In this excercise we will use the GRU unit since it only stores a single hidden value per neuron (LSTMs stores two) and is approximately twice as fast as the LSTM unit.\n",
    "\n",
    "As stated above we will implememt a Encoder-Decoder model. The simplest way to do this is to encode the input sequence using the Encoder model. We will then use the last hidden state of the Encoder $h^{enc}_T$ as input to the decoder model which then uses this information(simply a fixed length vector of numbers) to produce the targets. There is (at least)two ways to input $h^{enc}_T$ into the decoder\n",
    "\n",
    "1. Repeatly use $h^{enc}_T$ as input to the Decoder at each decode time step\n",
    "2. Intialize the decoder using $h^{enc}_T$ and run the decoder without any inputs\n",
    "\n",
    "In this excersize we will follow the first approach, beacause it's easier to implement. To do this need to create a lasagne layer that takes $h^{enc}_T$ and repeat it *N_decode_step* times. Below is an implementation of the RepeatLayer. You don't need to know the exact way it works, however make sure that you understand that it takes an input is size *(Batch_size x num_units)* and produces an output of size (Batch_size x n_decode_steps x num_units).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RepeatLayer(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, n, **kwargs):\n",
    "        '''\n",
    "        The input is expected to be a 2D tensor of shape \n",
    "        (num_batch, num_features). The input is repeated\n",
    "        n times such that the output will be \n",
    "        (num_batch, n, num_features)\n",
    "        '''\n",
    "        super(RepeatLayer, self).__init__(incoming, **kwargs)\n",
    "        self.n = n\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return tuple([input_shape[0], self.n] + list(input_shape[1:]))\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        #repeat the input n times\n",
    "        tensors = [input]*self.n\n",
    "        stacked = theano.tensor.stack(*tensors)\n",
    "        dim = [1, 0] + range(2, input.ndim + 1)\n",
    "        return stacked.dimshuffle(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "Since RNN models can be very slow to train on real large datasets we will generate some simpler training data for this exercise. The task for the RNN is simply to translate a string of letters spelling the numbers between 0-9 into the corresponding numbers i.e\n",
    "\n",
    "\"one two five\" --> \"125#\" (we use # as a special stop of sequence character)\n",
    "\n",
    "To input the strings into the RNN model we translate the characters into a vector integers using a simple translation table (i.e. 'h'->16, 'o'-> 17 etc). The code below prints a few input/output pairs using the *get_batch* function which randomy produces the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "inputs, input_masks, targets, target_masks, text_inputs, text_targets = \\\n",
    "    get_batch(batch_size=batch_size,max_digits=2,min_digits=1)\n",
    "\n",
    "print \"input types:\", inputs.dtype,  input_masks.dtype, targets.dtype, target_masks.dtype\n",
    "print print_valid_characters()\n",
    "print \"Stop character = #\"\n",
    "\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print \"\\nSAMPLE\",i\n",
    "    print \"TEXT INPUTS:\\t\\t\", text_inputs[i]\n",
    "    print \"TEXT TARGETS:\\t\\t\", text_targets[i]\n",
    "    print \"ENCODED INPUTS:\\t\\t\", inputs[i]\n",
    "    print \"MASK INPUTS:\\t\\t\", input_masks[i]\n",
    "    print \"ENCODED TARGETS:\\t\", targets[i]\n",
    "    print \"MASK TARGETS:\\t\\t\", target_masks[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder model setup\n",
    "Below is the Lasagne model definition. We use an embedding layer to go from integer representation to vector representation of the input.\n",
    "\n",
    "Note that the layer has a lot of print statements which we used for debugging during setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_UNITS_ENC = 10\n",
    "NUM_UNITS_DEC = 10\n",
    "MAX_DIGITS = 20 \n",
    "MIN_DIGITS = MAX_DIGITS #currently only support for same length outputs - we'll leave it for an exercise to add support for varying length targets\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "\n",
    "#symbolic theano variables. Note that we are using imatrix for X since it goes into the embedding layer\n",
    "x_sym = T.imatrix()\n",
    "y_sym = T.imatrix()\n",
    "xmask_sym = T.matrix()\n",
    "\n",
    "#dummy data to test implementation - We advise to check the output-dimensions of all layers.\n",
    "#One way to do this in lasagne/theano is to forward pass some data through the model and \n",
    "#check the output dimensions of these.\n",
    "#Create some random testdata\n",
    "X = np.random.randint(0,10,size=(BATCH_SIZE,MIN_DIGITS)).astype('int32')\n",
    "Xmask = np.ones((BATCH_SIZE,MIN_DIGITS)).astype('float32')\n",
    "\n",
    "##### ENCODER START #####\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "#Here we'll remove the trainable parameters from the embeding layer to constrain \n",
    "#it to a simple \"one-hot-encoding\". You can experiment with removing this line\n",
    "l_emb.params[l_emb.W].remove('trainable') \n",
    "#forward pass some data throug the inputlayer-embedding layer and print the output shape\n",
    "print lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).eval({x_sym: X}).shape\n",
    "\n",
    "l_mask_enc = lasagne.layers.InputLayer((None, None))\n",
    "l_enc = lasagne.layers.GRULayer(l_emb, num_units=NUM_UNITS_ENC, name='GRUEncoder', mask_input=l_mask_enc)\n",
    "print lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "# slice last index of dimension 1\n",
    "l_last_hid = lasagne.layers.SliceLayer(l_enc, indices=-1, axis=1)\n",
    "print lasagne.layers.get_output(l_last_hid, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "##### END OF ENCODER######\n",
    "\n",
    "\n",
    "##### START OF DECODER######\n",
    "l_in_rep = RepeatLayer(l_last_hid, n=MAX_DIGITS+1) #we add one to allow space for the end of sequence character\n",
    "print lasagne.layers.get_output(l_in_rep, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "l_dec = lasagne.layers.GRULayer(l_in_rep, num_units=NUM_UNITS_DEC, name='GRUDecoder')\n",
    "print lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "\n",
    "# We need to do some reshape voodo to connect a softmax layer to the decoder.\n",
    "# See http://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#examples \n",
    "# In short this line changes the shape from \n",
    "# (batch_size, decode_len, num_dec_units) -> (batch_size*decodelen,num_dec_units). \n",
    "# We need to do this since the softmax is applied to the last dimension and we want to \n",
    "# softmax the output at each position individually\n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_dec, (-1, [2]))\n",
    "print lasagne.layers.get_output(l_reshape, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "l_softmax = lasagne.layers.DenseLayer(l_reshape, num_units=NUM_OUTPUTS, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                      name='SoftmaxOutput')\n",
    "print lasagne.layers.get_output(l_softmax, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "# reshape back to 3d format (batch_size, decode_len, num_dec_units). Here we tied the batch size to the shape of the symbolic variable for X allowing \n",
    "#us to use different batch sizes in the model.\n",
    "l_out = lasagne.layers.ReshapeLayer(l_softmax, (x_sym.shape[0], -1, NUM_OUTPUTS))\n",
    "print lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "###END OF DECODER######\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cost function and theano functions\n",
    "Becasue the targets are categorical we use cross entropy error. We use the Adam optimizer but you\n",
    "can experiment with the different optimizers implemented in [Lasagne](http://lasagne.readthedocs.org/en/latest/modules/updates.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_decoder_train = lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, \n",
    "                                                deterministic=False)\n",
    "\n",
    "#cost function\n",
    "total_cost = T.nnet.categorical_crossentropy(\n",
    "    T.reshape(output_decoder_train, (-1, NUM_OUTPUTS)), y_sym.flatten())\n",
    "mean_cost = T.mean(total_cost)\n",
    "#accuracy function\n",
    "argmax = T.argmax(output_decoder_train,axis=-1)\n",
    "eq = T.eq(argmax,y_sym)\n",
    "acc = T.mean(eq)  # gives float64 because eq is uint8, T.cast(eq, 'float32') will fix that...\n",
    "\n",
    "#Get parameters of both encoder and decoder\n",
    "all_parameters = lasagne.layers.get_all_params([l_out], trainable=True)\n",
    "\n",
    "print \"Trainable Model Parameters\"\n",
    "print \"-\"*40\n",
    "for param in all_parameters:\n",
    "    print param, param.get_value().shape\n",
    "print \"-\"*40\n",
    "\n",
    "#add grad clipping to avoid exploding gradients\n",
    "all_grads = [T.clip(g,-3,3) for g in T.grad(mean_cost, all_parameters)]\n",
    "all_grads = lasagne.updates.total_norm_constraint(all_grads,3)\n",
    "\n",
    "#Compile Theano functions.\n",
    "#The two first two inputs to theano.functions is \n",
    "#1) a list of theano shared variables and \n",
    "#2) a list of functions(graphs) to calculate the values of most importanly the cost function. \n",
    "#3) for the training function the update argument should be given as the output from one of \n",
    "#4) lasagnes optimizers. of this argument is not set no parameters will be updated and only the values if 2) will be calculated\n",
    "updates = lasagne.updates.adam(all_grads, all_parameters, learning_rate=0.005)\n",
    "train_func = theano.function([x_sym, y_sym, xmask_sym], [mean_cost, acc, output_decoder_train], updates=updates)\n",
    "#since we don't have any stochasticity in the network we will just use the training graph without any updates given\n",
    "test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate some validation data\n",
    "Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_interval = 5000\n",
    "samples_to_process = 3e5\n",
    "samples_processed = 0\n",
    "\n",
    "val_samples = []\n",
    "costs, accs = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        inputs, input_masks, targets, target_masks, _, _ = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        batch_cost, batch_acc, batch_output = train_func(inputs, targets, input_masks)\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        #validation data\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print \"validating\"\n",
    "            val_acc, val_output = test_func(Xval, Yval, Xmask_val)\n",
    "            val_samples += [samples_processed]\n",
    "            accs += [val_acc]\n",
    "            plt.plot(val_samples,accs)\n",
    "            plt.ylabel('Validation Accuracy', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "            plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(np.mean(np.argmax(val_output,axis=2)==Yval,axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plot look like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot training cost\n",
    "#plt.figure(figsize=(7,7))\n",
    "#plt.plot(costs)\n",
    "#plt.ylabel('Cost', fontsize=15)\n",
    "#plt.xlabel('Number of updates', fontsize=15)\n",
    "#plt.title('Training', fontsize=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "1. What is the final validation performance ?, why do you think it is not better? Comment on the accuracy for each position in of the output symbols?\n",
    "\n",
    "2. Why do you think the validation performance looks more \"jig-saw\" like compared to FFN and CNN models?\n",
    "\n",
    "3. Optional: Bidirectional Encoder, In Lasagne bidirectional RNNs are implementated by running a forward model and a backward model separately and then concatenating them before parsing them on to the next layer. You can experiment with using a different merging layer than concat e.g. sum or multiplication see [lasagne merge layers [lasagne merge layers](http://lasagne.readthedocs.org/en/latest/modules/layers/merge.html).\n",
    "\n",
    "```\n",
    "l_rec_fwd = lasagne.layers.GRULayer(...,backwards=False)\n",
    "l_rec_bwd = lasagne.layers.GRULayer(...,backwards=True)\n",
    "l_rec = lasagne.layers.ConcatLayer([l_rec_fwd, l_rec_bwd], axis=2))\n",
    "```\n",
    "\n",
    "4. Optional: Add support for different lengths of targets (hint: add the target_mask to the cost function and only calculate the cost for the non-masked targets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention Decoder (LSTM)\n",
    "Selective attention for recurrent neural networks have recently attracted a lot of interest. These methods let the Decoder model selective select which part of the encoder sequence it will use for each decoded output symbol. This relieves the encoder from having to compress the input sequence into a fixed size vector representation passed on to the decoder. Secondly we can interrogate the decoder network about where it attends while producing the ouputs. below we'll implement an LSTM-decoder with selective attention and show that it significantly improves the performance of the toy translation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from decoder_attention import LSTMAttentionDecodeFeedbackLayer\n",
    "\n",
    "# you can acces the attetion weights alpha by adding l_dec.alpha \n",
    "# to the output variables in the theano function\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_UNITS_ENC = 10\n",
    "NUM_UNITS_DEC = 10\n",
    "MAX_DIGITS = 20 \n",
    "MIN_DIGITS = MAX_DIGITS #currently only support for same length outputs - we'll leave it for an exercise to add support for varying length targets\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "\n",
    "x_sym = T.imatrix()\n",
    "y_sym = T.imatrix()\n",
    "xmask_sym = T.matrix()\n",
    "    \n",
    "\n",
    "#dummy data to test implementation\n",
    "#X = np.random.randint(0,10,size=(BATCH_SIZE,15)).astype('int32')\n",
    "#Xmask = np.ones((BATCH_SIZE,NUM_INPUTS)).astype('float32')\n",
    "\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "##### ENCODER START #####\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "#Here we'll remove the trainable parameters from the embeding layer to constrain \n",
    "#it to a simple \"one-hot-encoding\". You can experiment with removing this line\n",
    "l_emb.params[l_emb.W].remove('trainable') \n",
    "print lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).eval(\n",
    "    {x_sym: X}).shape\n",
    "T.grad(lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_emb, trainable=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l_mask_enc = lasagne.layers.InputLayer((None, None))\n",
    "l_enc = lasagne.layers.GRULayer(l_emb, num_units=NUM_UNITS_ENC, name='GRUEncoder', mask_input=l_mask_enc)\n",
    "print lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_enc, trainable=True))\n",
    "####END OF ENCODER######\n",
    "\n",
    "\n",
    "####START OF DECODER######\n",
    "#note that the decoder have its own input layer, we'll use that to plug in the output \n",
    "#from the encoder later\n",
    "l_dec = LSTMAttentionDecodeFeedbackLayer(l_enc,\n",
    "                                        num_units=NUM_UNITS_DEC, \n",
    "                                        aln_num_units=20,\n",
    "                                        n_decodesteps=MAX_DIGITS+1,\n",
    "                                        name='LSTMDecoder')\n",
    "print lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_dec, trainable=True))\n",
    "\n",
    "# We need to do some reshape voodo to connect a softmax layer to the decoder.\n",
    "# See http://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#examples \n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_dec, (-1, [2]))\n",
    "l_softmax = lasagne.layers.DenseLayer(l_reshape, num_units=NUM_OUTPUTS, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                      name='SoftmaxOutput')\n",
    "# print lasagne.layers.get_output(l_softmax, x_sym).eval({x_sym: X}).shape\n",
    "# reshape back to 3d format (here we tied the batch size to the shape of the symbolic variable for X allowing \n",
    "#us to use different batch sizes in the model)\n",
    "l_out = lasagne.layers.ReshapeLayer(l_softmax, (x_sym.shape[0], -1, NUM_OUTPUTS))\n",
    "print lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, deterministic=False).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_dec, trainable=True))\n",
    "\n",
    "print \"\"\n",
    "###END OF DECODER######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate some validation data\n",
    "Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get output of encoder using X and Xmask as input\n",
    "output_decoder_train = lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, \n",
    "                                                 deterministic=False)\n",
    "\n",
    "#cost function\n",
    "total_cost = T.nnet.categorical_crossentropy(\n",
    "    T.reshape(output_decoder_train, (-1, NUM_OUTPUTS)), y_sym.flatten())\n",
    "mean_cost = T.mean(total_cost)\n",
    "#accuracy function\n",
    "acc = T.mean(T.eq(T.argmax(output_decoder_train,axis=-1),y_sym))\n",
    "\n",
    "#Get parameters of both encoder and decoder\n",
    "all_parameters = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "\n",
    "print \"Trainable Model Parameters\"\n",
    "print \"-\"*40\n",
    "for param in all_parameters:\n",
    "    print param, param.get_value().shape\n",
    "print \"-\"*40\n",
    "\n",
    "#add grad clipping to avoid exploding gradients\n",
    "all_grads = [T.clip(g,-3,3) for g in T.grad(mean_cost, all_parameters)]\n",
    "all_grads = lasagne.updates.total_norm_constraint(all_grads,3)\n",
    "\n",
    "#Compile Theano functions\n",
    "updates = lasagne.updates.adam(all_grads, all_parameters, learning_rate=0.005)\n",
    "train_func = theano.function([x_sym, y_sym, xmask_sym], [mean_cost, acc, output_decoder_train], updates=updates)\n",
    "#since we don't have any stochasticity in the network we will just use the training graph without any updates given\n",
    "test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train, l_dec.alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_interval = 5000\n",
    "samples_to_process = 1.5e5\n",
    "samples_processed = 0\n",
    "val_samples = []\n",
    "costs, accs = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        inputs, input_masks, targets, target_masks, _, _ = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        batch_cost, batch_acc, batch_output = train_func(inputs, targets, input_masks)\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        #print i, samples_processed\n",
    "        #validation data\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print \"validating\"\n",
    "            val_acc, val_output, alpha = test_func(Xval, Yval, Xmask_val)\n",
    "            val_samples += [samples_processed]\n",
    "            accs += [val_acc]\n",
    "            plt.plot(val_samples,accs)\n",
    "            plt.ylabel('', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('Validation Accuracy', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "            plt.show()\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(np.mean(np.argmax(val_output,axis=2)==Yval,axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plot look like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot of average attention weight as a function of the sequence position for each of \n",
    "#the 21 targets in the output sequence i.e. each line is the mean postion of the \n",
    "#attention for each target position.\n",
    "\n",
    "np.mean(alpha,axis=0).shape\n",
    "plt.figure()\n",
    "plt.plot(np.mean(alpha,axis=0).T)\n",
    "plt.ylabel('alpha', fontsize=15)\n",
    "plt.xlabel('Input Sequence position', fontsize=15)\n",
    "plt.title('Alpha weights', fontsize=20)\n",
    "plt.legend(map(str,range(1,22)), bbox_to_anchor=(1.125,1.0), fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
